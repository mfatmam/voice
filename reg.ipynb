{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfatmam/voice/blob/main/reg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cs0hlq9usSw7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODffyEkIsZKy"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/voice.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6Fr4o_7scW7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6oEvUAkswvP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "P4Kj6n9ys8w_",
        "outputId": "2ca24075-9379-4441-fc45-acfef072fbac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyaudio\n",
            "  Downloading PyAudio-0.2.14.tar.gz (47 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyaudio\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pyaudio\n",
            "\u001b[31mERROR: Could not build wheels for pyaudio, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2cf7828b-f32b-414e-a6e8-169c12af3e45\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2cf7828b-f32b-414e-a6e8-169c12af3e45\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving audio.wav to audio.wav\n",
            "{'meanfreq': 0.251124, 'sd': 0.115273, 'median': 0.010975, 'Q25': 0.000229, 'Q75': 0.042946, 'IQR': 0.014558, 'skew': 0.141735, 'kurt': 9.244614422999266, 'sp.ent': 0.981997, 'sfm': 0.036876, 'mode': 0.0, 'centroid': 0.251124, 'meanfun': 0.055565, 'minfun': 0.009775, 'maxfun': 0.279114, 'meandom': 2.957682, 'mindom': 0.458984, 'maxdom': 21.867188, 'dfrange': 21.84375, 'modindx': 0.0049039572}\n"
          ]
        }
      ],
      "source": [
        "!pip install pyaudio\n",
        "import librosa\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "from scipy.signal import find_peaks\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "def extract_voice_features(signal, sample_rate):\n",
        "    # meanfreq\n",
        "    meanfreq = np.mean(np.abs(librosa.core.stft(signal)))\n",
        "\n",
        "    # sd (standard deviation of frequency)\n",
        "    sd = np.std(np.abs(librosa.core.stft(signal)))\n",
        "\n",
        "    # median\n",
        "    median = np.median(np.abs(librosa.core.stft(signal)))\n",
        "\n",
        "    # Q25 et Q75\n",
        "    q25, q75 = np.percentile(signal, [25, 75])\n",
        "\n",
        "    # IQR (interquantile range)\n",
        "    iqr = q75 - q25\n",
        "\n",
        "    # skew et kurt\n",
        "    skewness = skew(signal)\n",
        "    kurtosis_value = kurtosis(signal)\n",
        "\n",
        "    # sp.ent (spectral entropy)\n",
        "    magnitude_spectrum = np.abs(librosa.core.stft(signal))\n",
        "    normalized_spectrum = magnitude_spectrum / np.sum(magnitude_spectrum)\n",
        "    spectral_entropy = -np.sum(normalized_spectrum * np.log2(normalized_spectrum + 1e-12))\n",
        "\n",
        "    # sfm (spectral flatness)\n",
        "    sfm = np.mean(librosa.feature.spectral_flatness(y=signal))\n",
        "\n",
        "    # mode (mode frequency)\n",
        "    mode = np.mean(librosa.feature.mfcc(y=signal, sr=sample_rate))\n",
        "\n",
        "    # centroid (frequency centroid)\n",
        "    centroid = np.mean(librosa.feature.spectral_centroid(y=signal, sr=sample_rate))\n",
        "\n",
        "\n",
        "\n",
        "    # meanfun (average of fundamental frequency)\n",
        "    mean_fun = np.mean(librosa.feature.rms(y=signal))\n",
        "\n",
        "    # minfun et maxfun\n",
        "    min_fun = np.min(signal)\n",
        "    max_fun = np.max(signal)\n",
        "\n",
        "    # meandom (average of dominant frequency)\n",
        "    peaks, _ = find_peaks(np.abs(signal))\n",
        "    mean_dom = np.mean(peaks) if len(peaks) > 0 else 0  # Utilisation de la moyenne des pics\n",
        "\n",
        "    # mindom (minimum of dominant frequency)\n",
        "    min_dom = np.min(peaks) if len(peaks) > 0 else 0  # Utilisation du minimum des pics\n",
        "\n",
        "    # maxdom (maximum of dominant frequency)\n",
        "    max_dom = np.max(peaks) if len(peaks) > 0 else 0  # Utilisation du maximum des pics\n",
        "\n",
        "    # dfrange (range of dominant frequency)\n",
        "    dfrange = max_dom - min_dom\n",
        "\n",
        "    # modindx (modulation index)\n",
        "    mod_indx = np.mean(np.abs(np.diff(signal))) / (np.max(signal) - np.min(signal))\n",
        "\n",
        "    # Créer un dictionnaire de caractéristiques\n",
        "    features = {\n",
        "        'meanfreq': meanfreq,\n",
        "        'sd': sd,\n",
        "        'median': median,\n",
        "        'Q25': q25,\n",
        "        'Q75': q75,\n",
        "        'IQR': iqr,\n",
        "        'skew': skewness,\n",
        "        'kurt': kurtosis_value,\n",
        "        'sp.ent': spectral_entropy,\n",
        "        'sfm': sfm,\n",
        "        'mode': mode,\n",
        "        'centroid': centroid,\n",
        "        'meanfun': mean_fun,\n",
        "        'minfun': min_fun,\n",
        "        'maxfun': max_fun,\n",
        "        'meandom': mean_dom,\n",
        "        'mindom': min_dom,\n",
        "        'maxdom': max_dom,\n",
        "        'dfrange': dfrange,\n",
        "        'modindx': mod_indx\n",
        "    }\n",
        "\n",
        "    return features\n",
        "    # Ajoutez ceci dans la fonction extract_voice_features\n",
        "#print(\"Peak Frequency in extract_voice_features:\", peakf)\n",
        "\n",
        "\n",
        "# Exemple d'utilisation\n",
        "uploaded = files.upload()\n",
        "audio_path = 'audio.wav'  # Assurez-vous de remplacer cela par le nom de votre fichier audio\n",
        "\n",
        "# Charger le fichier audio et extraire les caractéristiques\n",
        "signal, sample_rate = librosa.load(audio_path, sr=None)\n",
        "voice_features = extract_voice_features(signal, sample_rate)\n",
        "# Définir les ranges des caractéristiques\n",
        "feature_ranges = {\n",
        "    'meanfreq': {'min': 0.039363, 'max': 0.251124},\n",
        "    'sd': {'min': 0.018363, 'max': 0.115273},\n",
        "    'median': {'min': 0.010975, 'max': 0.261224},\n",
        "    'Q25': {'min': 0.000229, 'max': 0.247347},\n",
        "    'Q75': {'min': 0.042946, 'max': 0.273469},\n",
        "    'IQR': {'min': 0.014558, 'max': 0.252225},\n",
        "    'skew': {'min': 0.141735, 'max': 34.725453},\n",
        "    'kurt': {'min': 2.068455, 'max': 1309.612887},\n",
        "    'sp.ent': {'min': 0.738651, 'max': 0.981997},\n",
        "    'sfm': {'min': 0.036876, 'max': 0.842936},\n",
        "    'mode': {'min': 0.0, 'max': 0.28},\n",
        "    'centroid': {'min': 0.039363, 'max': 0.251124},\n",
        "    'peakf': {'min': 0.103093, 'max': 0.279114},\n",
        "    'meanfun': {'min': 0.055565, 'max': 0.237636},\n",
        "    'minfun': {'min': 0.009775, 'max': 0.204082},\n",
        "    'maxfun': {'min': 0.103093, 'max': 0.279114},\n",
        "    'meandom': {'min': 0.007812, 'max': 2.957682},\n",
        "    'mindom': {'min': 0.004883, 'max': 0.458984},\n",
        "    'maxdom': {'min': 0.007812, 'max': 21.867188},\n",
        "    'dfrange': {'min': 0.0, 'max': 21.84375},\n",
        "    'modindx': {'min': 0.0, 'max': 0.932374},\n",
        "}\n",
        "\n",
        "# Appliquer les conditions aux valeurs des caractéristiques\n",
        "for feature in voice_features:\n",
        "    if voice_features[feature] < feature_ranges[feature]['min']:\n",
        "        voice_features[feature] = feature_ranges[feature]['min']\n",
        "    elif voice_features[feature] > feature_ranges[feature]['max']:\n",
        "        voice_features[feature] = feature_ranges[feature]['max']\n",
        "\n",
        "#import pandas as pd\n",
        "\n",
        "# Supposons que 'new_data' est un dictionnaire contenant les nouvelles données\n",
        "#new_data =voice_features\n",
        "\n",
        "# Convertir le dictionnaire en DataFrame\n",
        "#new_row = pd.DataFrame([new_data.values])\n",
        "\n",
        "# Ajouter la nouvelle ligne au DataFrame existant\n",
        "#df = df.append(new_row, ignore_index=True)\n",
        "\n",
        "#import pandas as pd\n",
        "\n",
        "#Charger la base de données CSV dans un DataFrame\n",
        "#df = pd.read_csv('voice.csv')\n",
        "\n",
        "# Supprimer une ligne en fonction d'une condition (remplacez 'condition_column' et 'condition_value' par les valeurs appropriées)\n",
        "#condition_column = voice_features\n",
        "#condition_value = voice_features\n",
        "\n",
        "# Formuler la condition pour supprimer la ligne\n",
        "#condition = (df[condition_column] == condition_value)\n",
        "\n",
        "# Supprimer la ligne qui satisfait la condition\n",
        "#df = df[~condition]\n",
        "\n",
        "# Enregistrer le DataFrame mis à jour dans le fichier CSV\n",
        "#df.to_csv('voice.csv', index=False)\n",
        "\n",
        "\n",
        "# Afficher les caractéristiques après application des conditions\n",
        "print(voice_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbZLw3REtRWY",
        "outputId": "161483fe-e18b-4950-90de-b4866a762486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.51124000e-01 1.15273000e-01 1.09750000e-02 2.29000000e-04\n",
            " 4.29460000e-02 1.45580000e-02 1.41735000e-01 9.24461442e+00\n",
            " 9.81997000e-01 3.68760000e-02 0.00000000e+00 2.51124000e-01\n",
            " 5.55650000e-02 9.77500000e-03 2.79114000e-01 2.95768200e+00\n",
            " 4.58984000e-01 2.18671880e+01 2.18437500e+01 4.90395725e-03]\n"
          ]
        }
      ],
      "source": [
        "valeurs_array = np.array(list(voice_features.values()))\n",
        "print (valeurs_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFbeqlUSzRaM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzn2brpftXiu",
        "outputId": "481b438c-a6fa-4555-b9c5-87f68bfca06e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 57ms/step\n",
            "Prédiction de genre : [0.251124, 0.115273, 0.010975, 0.000229, 0.042946, 0.014558, 0.141735, 9.244614422999266, 0.981997, 0.036876, 0.0, 0.251124, 0.055565, 0.009775, 0.279114, 2.957682, 0.458984, 21.867188, 21.84375, 0.00490395724773407, 'Male']\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJuIE5u21IOF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "Sih3dynRtgbq",
        "outputId": "0fe92a50-bc99-4e80-df4b-db383ef50a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.2.2)\n",
            "Installing collected packages: pydub, gtts\n",
            "Successfully installed gtts-2.5.1 pydub-0.25.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "Accuracy: 0.9842271293375394\n",
            "La voix appartient à la base de données.\n",
            "Playing welcome message...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome message played.\n"
          ]
        }
      ],
      "source": [
        "# RF\n",
        "!pip install joblib\n",
        "!pip install pydub gtts\n",
        "!apt-get install -y ffmpeg\n",
        "!pip install pydub\n",
        "from IPython.display import Audio\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "from gtts import gTTS\n",
        "import pandas as pd\n",
        "import pygame\n",
        "import os\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Supposons que X contient les caractéristiques extraites de votre base de données et y contient les étiquettes correspondantes\n",
        "\n",
        "# Divisez les données en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialisez un modèle de forêt aléatoire (Random Forest)\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Entraînez le modèle sur l'ensemble d'entraînement\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Faites des prédictions sur l'ensemble de test\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Évaluez les performances du modèle\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "# Sauvegarder le modèle au format natif Keras\n",
        "\n",
        "# Charger le modèle\n",
        "from joblib import dump\n",
        "\n",
        "# Supposons que 'model' est votre modèle Random Forest entraîné\n",
        "dump(model, 'random_forest_model.joblib')\n",
        "\n",
        "\n",
        "# Maintenant, vous pouvez utiliser ce modèle pour classifier de nouvelles voix\n",
        "nouvelles_caracteristiques = valeurs_array.tolist() # Extrayez les caractéristiques de la nouvelle voix\n",
        "nouvelle_prediction = model.predict([nouvelles_caracteristiques])\n",
        "\n",
        "if nouvelle_prediction == 1:  # Supposons que 1 indique que la voix appartient à la base de données\n",
        "    print(\"La voix appartient à la base de données.\")\n",
        "    welcome_message = \"Welcome!\"\n",
        "    print(\"Playing welcome message...\")\n",
        "    tts = gTTS(welcome_message)\n",
        "    tts.save(\"/content/welcome_message.mp3\")  # Assurez-vous de sauvegarder dans /content/\n",
        "    display(Audio(\"/content/welcome_message.mp3\", autoplay=True))\n",
        "    print(\"Welcome message played.\")\n",
        "else:\n",
        "    print(\"La voix n'appartient pas à la base de données.\")\n",
        "    outsider_message = \"You are an outsider!\"\n",
        "    print(\"Playing outsider message...\")\n",
        "    tts = gTTS(outsider_message)\n",
        "    tts.save(\"/content/outsider_message.mp3\")  # Assurez-vous de sauvegarder dans /content/\n",
        "    display(Audio(\"/content/outsider_message.mp3\", autoplay=True))\n",
        "    print(\"Outsider message played.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0CSHQJk6LlS",
        "outputId": "da794a94-7aa2-4799-b5f1-acf79eccecff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQGKFFhmOeWJjqxYVov4ug",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}